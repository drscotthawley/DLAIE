{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7G8cv-d0eTXX"
   },
   "source": [
    "^ [CLICK HERE TO OPEN THIS NOTEBOOK IN COLAB](https://colab.research.google.com/github/drscotthawley/DLAIE/blob/main/Assignments/A2_Sample_NN.ipynb), then do **\"File > Save a Copy In Drive\" and edit it on your own.** \n",
    "\n",
    "...And then for grading, set your Colab notebook to \"Shareable\", and post the \"Sharing Link\" into the Google Form to which Dr. Hawley will email a link to the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZQAIZXgduCp"
   },
   "outputs": [],
   "source": [
    "!pip install numpy torch -Uqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHaftSJsdk8b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frvpAqx_gdlc"
   },
   "source": [
    "Create a PyTorch model of the Module class, call it MyNet, which will have two hidden layers of neurons.  Fill in your code on the lines between the `>>>>START` and `END<<<<` markings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNaKuotvd5no"
   },
   "outputs": [],
   "source": [
    "# GRADED EXERCISE 2.1\n",
    "class MyNet(nn.Module):    # leave the class definition & parameters alone\n",
    "    def __init__(self, \n",
    "        in_dim,      # dimensions of input (number columns for input)\n",
    "        hidden_dim1, # number of neurons in the 1st hidden layer\n",
    "        hidden_dim2, # number of neurons in the 2nd hidden layer\n",
    "        out_dim): # dimensions of output\n",
    "        super().__init__()  \n",
    "\n",
    "        # On the following lines, define 3 PyTorch nn.Linear layers to connect...\n",
    "        #   1. the input to the first hidden layer\n",
    "        #   2. the first hidden layer to the second hidden layer\n",
    "        #   3. the second hidden layer with the output\n",
    "        # You may name these whatever you like, but start them with \"self.\"\n",
    "        #>>>>START your code block below \n",
    "        \n",
    "\n",
    "\n",
    "        #<<<<END of your code block above\n",
    "\n",
    "    # In the forward method: pass the 'x' through the following successive steps\n",
    "    #  1. run 'x' through first layer you defined above\n",
    "    #  2. apply a \"torch.tanh\" activation to the result of step 1  (used to be F.tanh but they changed it!s)\n",
    "    #  3. run the result of step 2 through the second linear layer you defined\n",
    "    #  4. apply a \"F.relu\" activation to that\n",
    "    #  5. run that result through the third layer with no activation, and assign that to x\n",
    "    #  ...then we'll return x of that as your model's output\n",
    "    def forward(self, x): \n",
    "        #>>>>START your code block below          \n",
    "\n",
    "\n",
    "        #<<<<END of your code block above\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjWprrTDkpmx"
   },
   "source": [
    "We're just going to do random initialization, and random data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0lVYxT_ekmjO",
    "outputId": "74c77bb8-2636-422e-9cc2-7060e061e289"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4963, 0.7682, 0.0885],\n",
       "        [0.1320, 0.3074, 0.6341]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)   # initialize the random number generator\n",
    "\n",
    "batch_size, in_dim, out_dim = 2, 3, 1 \n",
    "x = torch.rand((batch_size, in_dim))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6JwGLh_mTfw"
   },
   "source": [
    "Now let's define a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C32wngA3lOCq"
   },
   "outputs": [],
   "source": [
    "hd1, hd2 = 20, 20    # hidden layer dimensions\n",
    "mynet = MyNet(in_dim, hd1, hd2, out_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnhiOCBhmbqK"
   },
   "source": [
    "And run our data through the model to obtain a set of predictions, \"preds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z2VzmCTwmVsp",
    "outputId": "273069a1-acd0-4494-a74d-fdf9c959d15f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1995],\n",
       "        [0.1767]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = mynet.forward(x)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpVMz8fRnAtJ"
   },
   "source": [
    "We got a number of predictions equal to `batch_size`.  The extra `grad_fn=` part we're not going to use in this assignment--it's needed for training the network but GitHub won't let us do that easily.\n",
    "\n",
    "To \"detach\" the gradient info, we just use the `.detach()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uBdRUFB0miND",
    "outputId": "67a13ff2-2209-4eee-9397-adf21dea377f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1995],\n",
       "        [0.1767]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZq6Ci0pn9As"
   },
   "source": [
    "And then if we want to do something with it using NumPy instead of PyTorch, there's a `.numpy()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j7ofV68JnkHz",
    "outputId": "bfd7fae7-3607-4bfc-aea2-94e2f0909b59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19950144],\n",
       "       [0.1766648 ]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = preds.detach().numpy(); p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzA1edJHoG99"
   },
   "source": [
    "^ the `dtype=float32` is just telling us that these numbers are 32-bit floating point numbers.  You don't need to do anything with that information.  If we use `print()` then we won't see that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VnF3mLfLoFjn",
    "outputId": "a7ed27d7-df17-456f-ccb9-17112c7b9a68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19950144]\n",
      " [0.1766648 ]]\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KETJBPmOooov"
   },
   "source": [
    "Now let's do some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PocU2_EAoTM_",
    "outputId": "97601a15-1860-4ba7-a20b-dac0e9bdca0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x2 =\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "x2 =\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "batch_size = 2, in_dim = 3\n"
     ]
    }
   ],
   "source": [
    "x2 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(\"x2 =\\n\",x2)\n",
    "x2 = x2.float() # actually let's make it floats instead of ints\n",
    "print(\"x2 =\\n\",x2)\n",
    "batch_size, in_dim = x2.shape[0], x2.shape[1]; \n",
    "print(f\"batch_size = {batch_size}, in_dim = {in_dim}\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "mynet2 = MyNet( in_dim, 10, 10, 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Lxp2m-xqLGd"
   },
   "source": [
    "And let's run it through "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BUjaWeNpoyO-",
    "outputId": "d10203b3-1e1a-42da-98cf-3f4540745373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.13569488]\n",
      " [-0.18428665]]\n"
     ]
    }
   ],
   "source": [
    "p2 = mynet2.forward(x2).detach().numpy()\n",
    "print(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TF1DI_RKrdMa"
   },
   "source": [
    "#### Assertion Check:\n",
    "This will be a way of testing whether your answers are close enough to those obtained by the instructor. If no output appears, it means you passed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "djF5zG54pkER"
   },
   "outputs": [],
   "source": [
    "tol = 1e-6   # some tolerable level of precision\n",
    "target = np.array([[-0.13569488], [-0.18428665]])  # my answer (to some precision based on cut & paste!)\n",
    "assert np.abs(p2 - target).sum() < tol, \"Nope the difference is too great.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eB1UaqtNrznk"
   },
   "outputs": [],
   "source": [
    "# Let me prepare some code to make this more convenient \n",
    "def check_preds(net, x, target, tol=1e-6):\n",
    "    preds = net.forward(x).detach().numpy()\n",
    "    assert np.abs(preds - target).sum() < tol, \"Nope the difference is too great.\"\n",
    "    print(\"Passed the test!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EF3KvXmztDWg",
    "outputId": "e1ac1b3d-3b2c-42f8-ad30-e2f86bdae7c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed the test!\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "net = MyNet(x2.shape[1], 10,10, target.shape[1])\n",
    "check_preds(net, x2, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjTQJlXiuVCw",
    "outputId": "5fedcb99-0bc3-44fb-8e61-849cd7bd7b16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed the test!\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x3 = torch.rand((3,4))   # a batch of 3 input vectors with 4 elements each\n",
    "net = MyNet(x3.shape[1], 30,30, 1)\n",
    "target = np.array([[-0.3079027 ],[-0.34663504],[-0.30993503]]) # what I got\n",
    "check_preds(net, x3, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q86d2DbSd3M8"
   },
   "source": [
    "# That's it for now\n",
    "We could go on and do more tests, and graphs, and samples of training.  Let's just see if we have this much working before moving on!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
